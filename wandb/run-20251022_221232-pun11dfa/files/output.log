10/22/2025 22:12:33 - INFO - __main__ - ***** Training arguments *****
10/22/2025 22:12:33 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='/ocean/projects/cis250019p/jye9/11685-project/data', is_cifar_10=True, image_size=32, batch_size=64, num_workers=4, num_classes=10, run_name='exp-1-ddpm', output_dir='/ocean/projects/cis250019p/jye9/11685-project/experiments', num_epochs=300, learning_rate=0.0005, weight_decay=0.0001, grad_clip=1.0, seed=42, mixed_precision='none', use_val=True, num_train_timesteps=1000, num_inference_steps=250, beta_start=0.0001, beta_end=0.02, beta_schedule='cosine', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, optimizer_type='AdamW', scheduler_type='ConsineAnnealingLR', unet_in_size=32, unet_in_ch=3, unet_ch=128, unet_ch_mult=[1, 2, 2, 4], unet_attn=[1, 2, 3], unet_num_res_blocks=2, unet_dropout=0.1, latent_ddpm=False, pretrained_vae='/ocean/projects/cis250019p/jye9/11685-project/pretrained/model.ckpt', use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt=None, device='cuda', rank=0, world_size=1, predictor_type='epsilon', distributed=False, local_rank=0, total_batch_size=64, max_train_steps=234300)
10/22/2025 22:12:33 - INFO - __main__ - ***** Running training *****
10/22/2025 22:12:33 - INFO - __main__ -   Num examples = 50000
10/22/2025 22:12:33 - INFO - __main__ -   Num Epochs = 300
10/22/2025 22:12:33 - INFO - __main__ -   Instantaneous batch size per device = 64
10/22/2025 22:12:33 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64
10/22/2025 22:12:33 - INFO - __main__ -   Total optimization steps per epoch 781
10/22/2025 22:12:33 - INFO - __main__ -   Total optimization steps = 234300
  0%|                                                                                                                                 | 0/234300 [00:00<?, ?it/s]10/22/2025 22:12:33 - INFO - __main__ - Epoch 1/300
  0%|                                                                                                                  | 1/234300 [02:37<10236:26:35, 157.28s/it]10/22/2025 22:15:10 - INFO - __main__ - Epoch 1/300, Step 780/781, Loss 0.07618381828069687 (0.1310043931770569)
10/22/2025 22:15:16 - INFO - __main__ - Epoch 1/300 Validation Loss: 0.065929
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 64.77it/s]
10/22/2025 22:15:20 - INFO - numexpr.utils - Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.3<00:00, 66.68it/s]
10/22/2025 22:15:20 - INFO - numexpr.utils - NumExpr defaulting to 16 threads.
10/22/2025 22:15:20 - INFO - __main__ - Epoch 2/300
  0%|                                                                                                                  | 2/234300 [05:24<10617:02:25, 163.13s/it]10/22/2025 22:17:57 - INFO - __main__ - Epoch 2/300, Step 780/781, Loss 0.058360934257507324 (0.06418132253954718)
10/22/2025 22:18:03 - INFO - __main__ - Epoch 2/300 Validation Loss: 0.060627
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 72.38it/s]
10/22/2025 22:18:07 - INFO - __main__ - Epoch 3/300██████████████████████████████████████████████████████████████████████████▌ | 247/250 [00:03<00:00, 72.61it/s]
  0%|                                                                                                                  | 3/234300 [08:10<10708:37:43, 164.54s/it]10/22/2025 22:20:44 - INFO - __main__ - Epoch 3/300, Step 780/781, Loss 0.056901559233665466 (0.06080234864495323)
10/22/2025 22:20:50 - INFO - __main__ - Epoch 3/300 Validation Loss: 0.057817
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 71.21it/s]
10/22/2025 22:20:53 - INFO - __main__ - Epoch 4/300██████████████████████████████████████████████████████████████████████████▌ | 247/250 [00:03<00:00, 71.30it/s]
  0%|                                                                                                                  | 4/234300 [10:56<10750:17:07, 165.18s/it]10/22/2025 22:23:30 - INFO - __main__ - Epoch 4/300, Step 780/781, Loss 0.057094596326351166 (0.05944009911311879)
10/22/2025 22:23:36 - INFO - __main__ - Epoch 4/300 Validation Loss: 0.057540
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 71.62it/s]
10/22/2025 22:23:39 - INFO - __main__ - Epoch 5/300██████████████████████████████████████████████████████████████████████████▌ | 247/250 [00:03<00:00, 71.76it/s]
  0%|                                                                                                                  | 5/234300 [13:43<10775:59:19, 165.58s/it]10/22/2025 22:26:16 - INFO - __main__ - Epoch 5/300, Step 780/781, Loss 0.07452359050512314 (0.0584421267306072)
10/22/2025 22:26:22 - INFO - __main__ - Epoch 5/300 Validation Loss: 0.055049
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 70.64it/s]
10/22/2025 22:26:26 - INFO - __main__ - Epoch 6/300██████████████████████████████████████████████████████████████████████████▌ | 247/250 [00:03<00:00, 70.79it/s]
  0%|                                                                                                                  | 6/234300 [16:29<10796:15:33, 165.89s/it]10/22/2025 22:29:03 - INFO - __main__ - Epoch 6/300, Step 780/781, Loss 0.06661804020404816 (0.057941898803742994)
10/22/2025 22:29:08 - INFO - __main__ - Epoch 6/300 Validation Loss: 0.055677
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 70.34it/s]
10/22/2025 22:29:12 - INFO - __main__ - Epoch 7/300██████████████████████████████████████████████████████████████████████████▌ | 247/250 [00:03<00:00, 70.34it/s]
  0%|                                                                                                                  | 7/234300 [19:16<10806:53:55, 166.05s/it]10/22/2025 22:31:49 - INFO - __main__ - Epoch 7/300, Step 780/781, Loss 0.06861516088247299 (0.05706957776800618)
10/22/2025 22:31:55 - INFO - __main__ - Epoch 7/300 Validation Loss: 0.055926
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 68.00it/s]
10/22/2025 22:31:59 - INFO - __main__ - Epoch 8/300██████████████████████████████████████████████████████████████████████████  | 246/250 [00:03<00:00, 69.70it/s]
  0%|                                                                                                                  | 8/234300 [22:02<10820:07:03, 166.26s/it]10/22/2025 22:34:36 - INFO - __main__ - Epoch 8/300, Step 780/781, Loss 0.032798200845718384 (0.05650989673125454)
10/22/2025 22:34:42 - INFO - __main__ - Epoch 8/300 Validation Loss: 0.056569
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 66.50it/s]
10/22/2025 22:34:45 - INFO - __main__ - Epoch 9/300█████████████████████████████████████████████████████████████████████████▌  | 245/250 [00:03<00:00, 66.41it/s]
  0%|                                                                                                                  | 9/234300 [24:49<10833:17:42, 166.46s/it]10/22/2025 22:37:23 - INFO - __main__ - Epoch 9/300, Step 780/781, Loss 0.045607905834913254 (0.057376372400151324)
10/22/2025 22:37:28 - INFO - __main__ - Epoch 9/300 Validation Loss: 0.056143
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 68.58it/s]
10/22/2025 22:37:32 - INFO - __main__ - Epoch 10/300████████████████████████████████████████████████████████████████████████▌  | 245/250 [00:03<00:00, 68.69it/s]
  0%|                                                                                                                 | 10/234300 [27:36<10834:20:27, 166.48s/it]10/22/2025 22:40:09 - INFO - __main__ - Epoch 10/300, Step 780/781, Loss 0.06886675953865051 (0.057344789994778)
10/22/2025 22:40:15 - INFO - __main__ - Epoch 10/300 Validation Loss: 0.059245
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 68.87it/s]
10/22/2025 22:40:19 - INFO - __main__ - Epoch 11/300█████████████████████████████████████████████████████████████████████████  | 246/250 [00:03<00:00, 69.50it/s]
  0%|                                                                                                                 | 11/234300 [30:22<10829:17:06, 166.40s/it]10/22/2025 22:42:55 - INFO - __main__ - Epoch 11/300, Step 780/781, Loss 0.05280579254031181 (0.05813912072346549)
10/22/2025 22:43:01 - INFO - __main__ - Epoch 11/300 Validation Loss: 0.057224
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 69.23it/s]
10/22/2025 22:43:05 - INFO - __main__ - Epoch 12/300████████████████████████████████████████████████████████████████████████   | 244/250 [00:03<00:00, 69.61it/s]
  0%|                                                                                                                 | 12/234300 [33:08<10831:19:34, 166.43s/it]10/22/2025 22:45:42 - INFO - __main__ - Epoch 12/300, Step 780/781, Loss 0.05379260703921318 (0.05771886523951336)
10/22/2025 22:45:48 - INFO - __main__ - Epoch 12/300 Validation Loss: 0.056313
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 67.56it/s]
10/22/2025 22:45:51 - INFO - __main__ - Epoch 13/300████████████████████████████████████████████████████████████████████████▌  | 245/250 [00:03<00:00, 67.62it/s]
