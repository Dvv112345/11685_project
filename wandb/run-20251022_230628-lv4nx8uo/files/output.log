10/22/2025 23:06:32 - INFO - __main__ - ***** Training arguments *****
10/22/2025 23:06:32 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='/ocean/projects/cis250019p/jye9/11685-project/data', is_cifar_10=True, image_size=32, batch_size=64, num_workers=4, num_classes=10, run_name='exp-7-ddpm', output_dir='/ocean/projects/cis250019p/jye9/11685-project/experiments', num_epochs=300, learning_rate=0.0001, weight_decay=0.02, grad_clip=1.0, seed=42, mixed_precision='none', use_val=True, num_train_timesteps=500, num_inference_steps=500, beta_start=0.0001, beta_end=0.01, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, optimizer_type='AdamW', scheduler_type='ConsineAnnealingLR', unet_in_size=32, unet_in_ch=3, unet_ch=64, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=2, unet_dropout=0.2, latent_ddpm=False, pretrained_vae='/ocean/projects/cis250019p/jye9/11685-project/pretrained/model.ckpt', use_cfg=False, cfg_guidance_scale=2, use_ddim=False, ckpt=None, device='cuda', rank=0, world_size=1, predictor_type='epsilon', distributed=False, local_rank=0, total_batch_size=64, max_train_steps=234300)
10/22/2025 23:06:32 - INFO - __main__ - ***** Running training *****
10/22/2025 23:06:32 - INFO - __main__ -   Num examples = 50000
10/22/2025 23:06:32 - INFO - __main__ -   Num Epochs = 300
10/22/2025 23:06:32 - INFO - __main__ -   Instantaneous batch size per device = 64
10/22/2025 23:06:32 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64
10/22/2025 23:06:32 - INFO - __main__ -   Total optimization steps per epoch 781
10/22/2025 23:06:32 - INFO - __main__ -   Total optimization steps = 234300
  0%|                                                                                                                                 | 0/234300 [00:00<?, ?it/s]10/22/2025 23:06:32 - INFO - __main__ - Epoch 1/300
  0%|                                                                                                                    | 1/234300 [01:05<4231:43:58, 65.02s/it]10/22/2025 23:07:37 - INFO - __main__ - Epoch 1/300, Step 780/781, Loss 0.051717765629291534 (0.25335599540729226)
10/22/2025 23:07:39 - INFO - __main__ - Epoch 1/300 Validation Loss: 0.073623
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 80.67it/s]
10/22/2025 23:07:46 - INFO - numexpr.utils - Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.6<00:00, 81.73it/s]
10/22/2025 23:07:46 - INFO - numexpr.utils - NumExpr defaulting to 16 threads.
10/22/2025 23:07:47 - INFO - __main__ - Epoch 2/300
