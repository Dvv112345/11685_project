10/22/2025 22:51:26 - INFO - __main__ - ***** Training arguments *****
10/22/2025 22:51:26 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='/ocean/projects/cis250019p/jye9/11685-project/data', is_cifar_10=True, image_size=32, batch_size=64, num_workers=4, num_classes=10, run_name='exp-5-ddpm', output_dir='/ocean/projects/cis250019p/jye9/11685-project/experiments', num_epochs=300, learning_rate=0.0001, weight_decay=0.02, grad_clip=1.0, seed=42, mixed_precision='none', use_val=True, num_train_timesteps=500, num_inference_steps=500, beta_start=0.0001, beta_end=0.01, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, optimizer_type='AdamW', scheduler_type='ConsineAnnealingLR', unet_in_size=32, unet_in_ch=3, unet_ch=64, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=2, unet_dropout=0.2, latent_ddpm=False, pretrained_vae='/ocean/projects/cis250019p/jye9/11685-project/pretrained/model.ckpt', use_cfg=False, cfg_guidance_scale=2, use_ddim=False, ckpt=None, device='cuda', rank=0, world_size=1, predictor_type='epsilon', distributed=False, local_rank=0, total_batch_size=64, max_train_steps=234300)
10/22/2025 22:51:26 - INFO - __main__ - ***** Running training *****
10/22/2025 22:51:26 - INFO - __main__ -   Num examples = 50000
10/22/2025 22:51:26 - INFO - __main__ -   Num Epochs = 300
10/22/2025 22:51:26 - INFO - __main__ -   Instantaneous batch size per device = 64
10/22/2025 22:51:26 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64
10/22/2025 22:51:26 - INFO - __main__ -   Total optimization steps per epoch 781
10/22/2025 22:51:26 - INFO - __main__ -   Total optimization steps = 234300
  0%|                                                                                                                                 | 0/234300 [00:00<?, ?it/s]10/22/2025 22:51:26 - INFO - __main__ - Epoch 1/300
  0%|                                                                                                                    | 1/234300 [01:05<4279:12:05, 65.75s/it]10/22/2025 22:52:32 - INFO - __main__ - Epoch 1/300, Step 780/781, Loss 0.05166592821478844 (0.2534788297334264)
10/22/2025 22:52:34 - INFO - __main__ - Epoch 1/300 Validation Loss: 0.073516
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 80.97it/s]
10/22/2025 22:52:41 - INFO - numexpr.utils - Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.6<00:00, 82.50it/s]
10/22/2025 22:52:41 - INFO - numexpr.utils - NumExpr defaulting to 16 threads.
10/22/2025 22:52:42 - INFO - __main__ - Epoch 2/300
  0%|                                                                                                                    | 2/234300 [02:20<4614:44:14, 70.91s/it]10/22/2025 22:53:46 - INFO - __main__ - Epoch 2/300, Step 780/781, Loss 0.07116494327783585 (0.07351086237652658)
10/22/2025 22:53:49 - INFO - __main__ - Epoch 2/300 Validation Loss: 0.068735
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 79.37it/s]
10/22/2025 22:53:55 - INFO - __main__ - Epoch 3/300██████████████████████████████████████████████████████████████████████████▊ | 494/499 [00:06<00:00, 79.17it/s]
  0%|                                                                                                                    | 3/234300 [03:33<4676:45:26, 71.86s/it]10/22/2025 22:54:59 - INFO - __main__ - Epoch 3/300, Step 780/781, Loss 0.06720174849033356 (0.06960930440589194)
10/22/2025 22:55:02 - INFO - __main__ - Epoch 3/300 Validation Loss: 0.064315
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 79.22it/s]
10/22/2025 22:55:08 - INFO - __main__ - Epoch 4/300██████████████████████████████████████████████████████████████████████████▊ | 494/499 [00:06<00:00, 79.71it/s]
  0%|                                                                                                                    | 4/234300 [04:46<4717:23:05, 72.48s/it]10/22/2025 22:56:13 - INFO - __main__ - Epoch 4/300, Step 780/781, Loss 0.0678238794207573 (0.06687565087776025)
10/22/2025 22:56:15 - INFO - __main__ - Epoch 4/300 Validation Loss: 0.063978
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 79.39it/s]
10/22/2025 22:56:21 - INFO - __main__ - Epoch 5/300███████████████████████████████████████████████████████████████████████████ | 495/499 [00:06<00:00, 79.36it/s]
  0%|                                                                                                                    | 5/234300 [05:59<4733:32:44, 72.73s/it]10/22/2025 22:57:26 - INFO - __main__ - Epoch 5/300, Step 780/781, Loss 0.0583706758916378 (0.06595082208037224)
10/22/2025 22:57:28 - INFO - __main__ - Epoch 5/300 Validation Loss: 0.062303
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 81.48it/s]
10/22/2025 22:57:34 - INFO - __main__ - Epoch 6/300██████████████████████████████████████████████████████████████████████████▊ | 494/499 [00:06<00:00, 81.43it/s]
  0%|                                                                                                                    | 6/234300 [07:12<4739:59:28, 72.83s/it]10/22/2025 22:58:39 - INFO - __main__ - Epoch 6/300, Step 780/781, Loss 0.042745333164930344 (0.0646631442649569)
10/22/2025 22:58:41 - INFO - __main__ - Epoch 6/300 Validation Loss: 0.063095
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 82.12it/s]
10/22/2025 22:58:47 - INFO - __main__ - Epoch 7/300██████████████████████████████████████████████████████████████████████████▊ | 494/499 [00:06<00:00, 83.04it/s]
  0%|                                                                                                                    | 7/234300 [08:26<4746:14:57, 72.93s/it]10/22/2025 22:59:52 - INFO - __main__ - Epoch 7/300, Step 780/781, Loss 0.07713378965854645 (0.06404069697105168)
10/22/2025 22:59:54 - INFO - __main__ - Epoch 7/300 Validation Loss: 0.058632
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 80.40it/s]
10/22/2025 23:00:01 - INFO - __main__ - Epoch 8/300██████████████████████████████████████████████████████████████████████████▌ | 493/499 [00:06<00:00, 80.49it/s]
  0%|                                                                                                                    | 8/234300 [09:39<4751:29:44, 73.01s/it]10/22/2025 23:01:05 - INFO - __main__ - Epoch 8/300, Step 780/781, Loss 0.06616038084030151 (0.06372381490148442)
10/22/2025 23:01:08 - INFO - __main__ - Epoch 8/300 Validation Loss: 0.063011
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 81.99it/s]
10/22/2025 23:01:14 - INFO - __main__ - Epoch 9/300██████████████████████████████████████████████████████████████████████████▊ | 494/499 [00:06<00:00, 81.79it/s]
  0%|                                                                                                                    | 9/234300 [10:53<4776:56:57, 73.40s/it]10/22/2025 23:02:20 - INFO - __main__ - Epoch 9/300, Step 780/781, Loss 0.07231071591377258 (0.06326156047562784)
10/22/2025 23:02:23 - INFO - __main__ - Epoch 9/300 Validation Loss: 0.061186
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499/499 [00:06<00:00, 81.32it/s]
10/22/2025 23:02:29 - INFO - __main__ - Epoch 10/300█████████████████████████████████████████████████████████████████████████▎ | 492/499 [00:06<00:00, 81.46it/s]
