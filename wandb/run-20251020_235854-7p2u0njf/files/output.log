10/20/2025 23:58:55 - INFO - __main__ - ***** Training arguments *****
10/20/2025 23:58:55 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='/ocean/projects/cis250019p/jye9/11685-project/data', image_size=32, batch_size=64, num_workers=4, num_classes=10, run_name='exp-8-ddpm', output_dir='/ocean/projects/cis250019p/jye9/11685-project/experiments', num_epochs=100, learning_rate=0.0001, weight_decay=0.01, grad_clip=1.0, seed=42, mixed_precision='none', num_train_timesteps=500, num_inference_steps=500, beta_start=0.0001, beta_end=0.01, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, optimizer_type='AdamW', scheduler_type='ConsineAnnealingLR', unet_in_size=32, unet_in_ch=3, unet_ch=64, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=1, unet_dropout=0.2, latent_ddpm=False, pretrained_vae='pretrained/model.ckpt', use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt=None, predictor_type='epsilon', distributed=False, world_size=1, rank=0, local_rank=0, device='cuda', total_batch_size=64, max_train_steps=78100)
10/20/2025 23:58:55 - INFO - __main__ - ***** Running training *****
10/20/2025 23:58:55 - INFO - __main__ -   Num examples = 50000
10/20/2025 23:58:55 - INFO - __main__ -   Num Epochs = 100
10/20/2025 23:58:55 - INFO - __main__ -   Instantaneous batch size per device = 64
10/20/2025 23:58:55 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64
10/20/2025 23:58:55 - INFO - __main__ -   Total optimization steps per epoch 781
10/20/2025 23:58:55 - INFO - __main__ -   Total optimization steps = 78100
  0%|                                                                                     | 0/78100 [00:00<?, ?it/s]10/20/2025 23:58:55 - INFO - __main__ - Epoch 1/100
  0%|                                                                          | 1/78100 [00:00<15:28:39,  1.40it/s]10/20/2025 23:58:56 - INFO - __main__ - Epoch 1/100, Step 0/781, Loss 0.9998959302902222 (0.9998959302902222)
  0%|                                                                         | 101/78100 [00:06<1:13:27, 17.70it/s]10/20/2025 23:59:02 - INFO - __main__ - Epoch 1/100, Step 100/781, Loss 0.8418871760368347 (0.897509490499402)
  0%|▏                                                                        | 201/78100 [00:12<1:13:19, 17.71it/s]10/20/2025 23:59:07 - INFO - __main__ - Epoch 1/100, Step 200/781, Loss 0.6484869122505188 (0.8390569520826957)
  0%|▎                                                                        | 301/78100 [00:17<1:13:11, 17.72it/s]10/20/2025 23:59:13 - INFO - __main__ - Epoch 1/100, Step 300/781, Loss 0.4582916498184204 (0.7314328143366944)
  1%|▎                                                                        | 401/78100 [00:23<1:12:42, 17.81it/s]10/20/2025 23:59:18 - INFO - __main__ - Epoch 1/100, Step 400/781, Loss 0.3465234637260437 (0.6550593990042917)
  1%|▍                                                                        | 501/78100 [00:28<1:12:14, 17.90it/s]10/20/2025 23:59:24 - INFO - __main__ - Epoch 1/100, Step 500/781, Loss 0.22048288583755493 (0.5774183849731606)
  1%|▌                                                                        | 601/78100 [00:34<1:12:27, 17.83it/s]10/20/2025 23:59:30 - INFO - __main__ - Epoch 1/100, Step 600/781, Loss 0.17824208736419678 (0.5170354920248819)
  1%|▋                                                                        | 701/78100 [00:40<1:12:50, 17.71it/s]10/20/2025 23:59:35 - INFO - __main__ - Epoch 1/100, Step 700/781, Loss 0.11081977933645248 (0.4628192560478896)
100%|████████████████████████████████████████████████████████████████████████████| 499/499 [00:04<00:00, 113.93it/s]
10/20/2025 23:59:44 - INFO - numexpr.utils - Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
10/20/2025 23:59:44 - INFO - numexpr.utils - NumExpr defaulting to 16 threads.
Checkpoint saved at /ocean/projects/cis250019p/jye9/11685-project/experiments/exp-8-ddpm/checkpoints/checkpoint_epoch_0.pth
10/20/2025 23:59:45 - INFO - __main__ - Epoch 2/100
10/20/2025 23:59:46 - INFO - __main__ - Epoch 2/100, Step 0/781, Loss 0.1350868046283722 (0.1350868046283722)
  1%|▊                                                                        | 881/78100 [00:56<1:12:50, 17.67it/s]10/20/2025 23:59:51 - INFO - __main__ - Epoch 2/100, Step 100/781, Loss 0.0707172304391861 (0.10218443942837196)
  1%|▉                                                                        | 981/78100 [01:01<1:12:46, 17.66it/s]10/20/2025 23:59:57 - INFO - __main__ - Epoch 2/100, Step 200/781, Loss 0.10291038453578949 (0.10012906244886455)
  1%|▉                                                                       | 1081/78100 [01:07<1:12:10, 17.79it/s]10/21/2025 00:00:03 - INFO - __main__ - Epoch 2/100, Step 300/781, Loss 0.1087503656744957 (0.09760718681289508)
  2%|█                                                                       | 1181/78100 [01:12<1:12:16, 17.74it/s]10/21/2025 00:00:08 - INFO - __main__ - Epoch 2/100, Step 400/781, Loss 0.10239577293395996 (0.09530663651941423)
  2%|█▏                                                                      | 1281/78100 [01:18<1:12:38, 17.62it/s]10/21/2025 00:00:14 - INFO - __main__ - Epoch 2/100, Step 500/781, Loss 0.07471533119678497 (0.09307023105090725)
  2%|█▏                                                                      | 1321/78100 [01:20<1:12:14, 17.71it/s]
