10/22/2025 13:45:40 - INFO - __main__ - ***** Training arguments *****
10/22/2025 13:45:40 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='../data/subset', is_cifar_10=False, image_size=32, batch_size=8, num_workers=2, num_classes=10, run_name='exp-2-ddpm', output_dir='/ocean/projects/cis250019p/jye9/11685-project/experiments', num_epochs=100, learning_rate=0.0005, weight_decay=0, grad_clip=1.0, seed=42, mixed_precision='none', use_val=False, num_train_timesteps=1000, num_inference_steps=50, beta_start=0.0001, beta_end=0.02, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, optimizer_type='AdamW', scheduler_type='ConsineAnnealingLR', unet_in_size=32, unet_in_ch=3, unet_ch=64, unet_ch_mult=[1, 2, 2, 2], unet_attn=[], unet_num_res_blocks=2, unet_dropout=0.0, latent_ddpm=False, pretrained_vae='/ocean/projects/cis250019p/jye9/11685-project/pretrained/model.ckpt', use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt=None, device='cuda', rank=0, world_size=1, predictor_type='epsilon', distributed=False, local_rank=0, total_batch_size=8, max_train_steps=700)
10/22/2025 13:45:40 - INFO - __main__ - ***** Running training *****
10/22/2025 13:45:40 - INFO - __main__ -   Num examples = 62
10/22/2025 13:45:40 - INFO - __main__ -   Num Epochs = 100
10/22/2025 13:45:40 - INFO - __main__ -   Instantaneous batch size per device = 8
10/22/2025 13:45:40 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
10/22/2025 13:45:40 - INFO - __main__ -   Total optimization steps per epoch 7
10/22/2025 13:45:40 - INFO - __main__ -   Total optimization steps = 700
  0%|                                                                                                                                    | 0/700 [00:00<?, ?it/s]10/22/2025 13:45:40 - INFO - __main__ - Epoch 1/100
  1%|▉                                                                                                                           | 5/700 [00:00<01:14,  9.30it/s]10/22/2025 13:45:41 - INFO - __main__ - Epoch 1/100, Step 6/7, Loss 0.9507493376731873 (0.9833379217556545)
10/22/2025 13:45:41 - INFO - __main__ - No validation loader configured (val_loader is None)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 110.52it/s]
10/22/2025 13:45:53 - INFO - numexpr.utils - Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.<00:00, 113.97it/s]
> /jet/home/jye9/Project/11685_project/train.py(586)main()
-> if is_primary(args):
True
> /jet/home/jye9/Project/11685_project/train.py(587)main()
-> print("sent")
sent
> /jet/home/jye9/Project/11685_project/train.py(588)main()
-> wandb_logger.log({'gen_images': wandb.Image(grid_image)})
10/22/2025 13:45:53 - INFO - numexpr.utils - NumExpr defaulting to 16 threads.
> /jet/home/jye9/Project/11685_project/train.py(591)main()
-> if epoch % 50 == 0:
  1%|█▏                                                                                                                          | 7/700 [00:20<01:14,  9.30it/s]
